{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ABC.txt', sep=',', header=0, parse_dates=['date_t'], \n",
    "                 date_parser=lambda d: pd.datetime.strptime(d, \"%Y/%m/%d %H\") if d!='date_t' else pd.NaT,\n",
    "                 dtype={'msisdn':str, 'imsi':str}) \n",
    "df.drop(df[df['date_t'].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(['msisdn', 'imsi', df['date_t'].dt.date]).size().reset_index(name='hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive_days(arr):\n",
    "    return (arr.iloc[-1] - arr.iloc[0]).days + 1\n",
    "\n",
    "def merge_consecutive_date(df):\n",
    "    sorted_date = df.sort_values(by=['date_t'])[['date_t', 'hours']]\n",
    "\n",
    "    consecutived = sorted_date['date_t']-pd.to_timedelta(1, unit='D') != sorted_date['date_t'].shift(1)\n",
    "    #if len(consecutived) > 1:\n",
    "    #    consecutived.iloc[0] = consecutived.iloc[1]\n",
    "    consecutived = consecutived.astype(np.int32)\n",
    "\n",
    "    merged_date = sorted_date.groupby(consecutived.cumsum(),as_index=False).agg({\n",
    "                                 'date_t':[('start_date', 'first'), ('days', consecutive_days)], \n",
    "                                 'hours':[('sum_hours','sum')]})\n",
    "    merged_date.columns = merged_date.columns.droplevel(0)\n",
    "\n",
    "    return merged_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grouped_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3c4de879d350>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmerged_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrouped_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'msisdn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'imsi'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_consecutive_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmerged_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grouped_df' is not defined"
     ]
    }
   ],
   "source": [
    "merged_df = grouped_df.groupby(['msisdn', 'imsi']).apply(merge_consecutive_date)\n",
    "merged_df = merged_df.reset_index(level=2, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(r'OB_UK_merged.csv', sep=',', header=True, index=True, na_rep='',\n",
    "                 columns=['start_date', 'days', 'sum_hours'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
